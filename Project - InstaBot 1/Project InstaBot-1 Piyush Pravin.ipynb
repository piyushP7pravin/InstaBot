{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the driver session\n",
    "driver = webdriver.Chrome()\n",
    "driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Login to Instagram Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visitng Instagram\n",
    "driver.get('https://www.instagram.com/')\n",
    "\n",
    "# Maximiaing the window for ease of view\n",
    "driver.maximize_window()\n",
    "\n",
    "# Explicitly waiting utill the login form is loaded completely\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"HmktE\")))\n",
    "\n",
    "# Login Credentials - username and password\n",
    "USERNAME = \"****************\"\n",
    "PASSWORD = \"****************\"\n",
    "\n",
    "# Locating the username text_field\n",
    "username_text_box = driver.find_element_by_name(\"username\")\n",
    "# Enter username in the text_field\n",
    "username_text_box.send_keys(USERNAME)\n",
    "\n",
    "time.sleep(2)\n",
    "# Locating the password text_field\n",
    "password_text_box = driver.find_element_by_name(\"password\")\n",
    "# Enter password in text_field\n",
    "password_text_box.send_keys(PASSWORD)\n",
    "\n",
    "# Explicitly waiting utill the login button is eanbled as initially it is disabled, then clicking on login button\n",
    "log_in = WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,\"//button[contains(@class,'L3NKy')]\")))\n",
    "log_in.click()\n",
    "\n",
    "# Now logged in to the instagram account\n",
    "\n",
    "# First a \"Turn on Notification\" window comes, so for now waiting till the window is loaded completely \n",
    "not_now = waiter=WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"HoLwm\")))\n",
    "# clicking on \"Not Now\"\n",
    "not_now.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Type for ‚Äúfood‚Äù in search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username  \t      |   Account Name\n",
      "-------------------------------------------\n",
      "foodtalkindia         |  Food Talk\n",
      "dilsefoodie           |  Karan Dua\n",
      "food__videos          |Food Videos\n",
      "yourfoodlab           |Your Food Lab\n",
      "food_travel_insider   |Arth Malviya|Food&amp;Travel Blog\n",
      "foodrush.recipe       |   FoodRush\n",
      "food                  |       Food\n",
      "rajshrifood           |Rajshri Food\n",
      "foodhallindia         |   Foodhall\n",
      "foodandwine           |Food &amp; Wine\n",
      "food_lovers_mad       | Foodlovers\n",
      "foodfusionpk          |Food Fusion\n",
      "foodmaniacindia       |Food Maniac India‚Ñ¢\n",
      "Horn Ok Please - Food Truck Festival|Jawarlal Nehru Stadium, Delhi, India\n",
      "Fun N Food Village    |Old Delhi Gurgaon Road Kapashera, New Delhi, India\n",
      "Food Frolic - Microbrewery &amp; Bar|FOOD FROLIC, 2nd Floor, Sapphire 83 Mall, Sector 83\n",
      "jollyfoodfellow       |Jolly Food Fellow\n",
      "foodie_incarnate      |Amar Sirohi (Food &amp; Fitness)\n",
      "mumbaifoodie          |Mumbai Foodie‚Ñ¢\n",
      "buzzfeedfood          |BuzzFeed Food\n",
      "foodbossindia         |Needa Khan‚ö°Ô∏è\n",
      "worldfoodprogramme    |World Food Programme\n",
      "food_terminal_        | Miss Kikki\n",
      "streetfoodrecipe      |facebook/Street Food Recipes\n",
      "fao                   |UN Food &amp; Agriculture Org\n",
      "foodiecouple_parvan   |Parth &amp; Vandana\n",
      "suyash_jain_official  |Doesn‚Äôt share food Ô£ø\n",
      "foodinsider           |Food Insider\n",
      "foodyviral            |Best Food Content üôã\n",
      "foodbloggerai         |   the FBAI\n",
      "foodcookery           |Food and Drinks\n",
      "howtofoodprep         |Healthy Food Prep üå±üç≥ü•óüçù\n",
      "healthyfoodadvice     |       Food\n",
      "delhifoodguide        |Delhi Food Guide\n",
      "foodjedi93            |  Food Jedi\n",
      "littlefooddaily       |Little Food Daily\n",
      "foodpandaindia        |foodpanda India\n",
      "hmm_nikhil            |Nikhil Chawla | Delhi Food\n",
      "foodiesince96         |MEHAK DHAWAN üíï\n",
      "_foodie_things_       |Food Stories\n",
      "loveanyfood           |Food | Tasty | Eat\n",
      "foodys                |       Food\n",
      "foodnetwork           |Food Network\n",
      "yourclickapp          |Food | Tasty | Recipe\n",
      "foo.dmaniac           |     Ayushi\n",
      "wholefoods            |Whole Foods Market\n",
      "littlefoodco          |The Little Food Co\n",
      "foodsile              |supply food üçè\n",
      "mumbaifoodscenes      |MUMBAI AND DUBAI FOOD SCENES\n",
      "bucketfoodjourney     |Tanvi | Lakshita | Yash\n",
      "ekplate               |ek Plate¬Æ - Food blog\n"
     ]
    }
   ],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "# writing \"food\" in search box\n",
    "search_box.send_keys(\"food\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "handles = driver.find_elements_by_xpath('//a[@class=\"yCE8d  \"]/div/div[2]/div/span')\n",
    "handle_names = driver.find_elements_by_xpath('//a[@class=\"yCE8d  \"]/div/div[2]/span')\n",
    "\n",
    "print(\"Username  \\t      |   Account Name\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(len(handles)):\n",
    "    print('{:<22s}|{:>11s}'.format(handles[i].get_attribute('innerHTML'),handle_names[i].get_attribute('innerHTML')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing the search box\n",
    "clear = driver.find_element_by_class_name(\"coreSpriteSearchClear\")\n",
    "clear.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Searching and Opening a profile \"So Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"30a7e63769c59e1d3830998e6e9c79bb\", element=\"30570bcd-c498-494d-bd45-0475721fd79a\")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"So Delhi\" in search box\n",
    "search_box.send_keys(\"So Delhi\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of So Delhi by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"So Delhi\":\n",
    "        i.click()\n",
    "        break\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Follow/Unfollow given handle - \"So Delhi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following \"So Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating the Follow/Following button\n",
    "# checking if already following or not\n",
    "\n",
    "follow = driver.find_element_by_xpath('//button[contains(@class, \"_6VtSN\")]')\n",
    "\n",
    "if follow.get_attribute(\"innerHTML\")==\"Follow\":\n",
    "    follow.click()\n",
    "else:\n",
    "    print('You are already following the page!')\n",
    "\n",
    "# explicitly waiting untill the follow process done and the button enables again\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfollowing \"So Delhi\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating the Follow/Following button\n",
    "# checking if already following or not\n",
    "\n",
    "\n",
    "if driver.find_element_by_xpath('//button[contains(@class, \"_6VtSN\")]').get_attribute(\"innerHTML\")==\"Follow\":\n",
    "    # if not folliwing then printing\n",
    "    print('You have already unfollowed the page')\n",
    "else:\n",
    "    #driver.find_element_by_xpath('//button[contains(@class, \"_6VtSN\")]/div/span').get_attribute(\"aria-label\")=='Following':\n",
    "    # following hence clicking on it to unfollow\n",
    "    unfollow = driver.find_element_by_class_name('_6VtSN')\n",
    "    unfollow.click()\n",
    "    \n",
    "    time.sleep(0.8)\n",
    "    # Explicitly waiting untill the unfollow button loads then click on unfollow\n",
    "    uf = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[contains(@class, \"-Cab_\")]')))\n",
    "    uf.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Like/Unlike posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching \"dilsefoodie\" and opening profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"dilsefoodie\" in search box\n",
    "search_box.send_keys(\"dilsefoodie\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of dilsefoodie by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"dilsefoodie\":\n",
    "        i.click()\n",
    "        break\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"30a7e63769c59e1d3830998e6e9c79bb\", element=\"fa22db77-296f-4ec7-a0e1-179fbfbb45b0\")>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.execute_script(\n",
    "    'window.scrollTo(0, document.body.scrollHeight);')\n",
    "driver.execute_script(\n",
    "    'window.scrollTo(0, document.body.scrollHeight);')\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"Nnq7C\")]/div/a/div[1]')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liking the top 30 posts of the ‚Äòdilsefoodie'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liked 0\n",
      "liked 1\n",
      "liked 2\n",
      "liked 3\n",
      "liked 4\n",
      "liked 5\n",
      "liked 6\n",
      "liked 7\n",
      "liked 8\n",
      "liked 9\n",
      "liked 10\n",
      "liked 11\n",
      "liked 12\n",
      "liked 13\n",
      "liked 14\n",
      "liked 15\n",
      "liked 16\n",
      "liked 17\n",
      "liked 18\n",
      "liked 19\n",
      "liked 20\n",
      "liked 21\n",
      "liked 22\n",
      "liked 23\n",
      "liked 24\n",
      "liked 25\n",
      "liked 26\n",
      "liked 27\n",
      "liked 28\n",
      "liked 29\n"
     ]
    }
   ],
   "source": [
    "#intializing count\n",
    "count=0\n",
    "\n",
    "#getting the list of all posts\n",
    "for i in driver.find_elements_by_xpath('//div[contains(@class, \"Nnq7C\")]/div/a/div[1]'):\n",
    "    #clicking on post and opening it\n",
    "    i.click()\n",
    "    \n",
    "    # explicitly waiting untill the like button is loaded\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//section[@class='ltpMr Slqrh']/span/button\")))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # locating like button\n",
    "    check = driver.find_element_by_xpath(\"//section[@class='ltpMr Slqrh']/span/button\")\n",
    "    \n",
    "    # getting the aria-label to check whether it is already liked or not\n",
    "    liked_unliked = BeautifulSoup(check.get_attribute('innerHTML'),'html.parser').find('svg').get('aria-label')\n",
    "    \n",
    "    #checking if it is liked or not\n",
    "    if liked_unliked==\"Like\":\n",
    "        check.click()\n",
    "        print(\"liked\",count)\n",
    "    else:\n",
    "        print(\"Aready Liked\",count)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # locating the cross button to go to back page\n",
    "    back = driver.find_element_by_xpath(\"//div[@class='_2dDPU CkGkG']/div[3]/button\")\n",
    "    # clicking on cross button\n",
    "    back.click()\n",
    "    \n",
    "    #explivitly waiting until the main page is loaded again\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"Nnq7C\")]/div/a/div[1]')))\n",
    "    \n",
    "    # increasing count by 1\n",
    "    count+=1\n",
    "    \n",
    "    # checking if 30 posts are liked or not\n",
    "    if count==30:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unliking the top 30 posts of the ‚Äòdilsefoodie'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unliked 0\n",
      "Unliked 1\n",
      "Unliked 2\n",
      "Unliked 3\n",
      "Unliked 4\n",
      "Unliked 5\n",
      "Unliked 6\n",
      "Unliked 7\n",
      "Unliked 8\n",
      "Unliked 9\n",
      "Unliked 10\n",
      "Unliked 11\n",
      "Unliked 12\n",
      "Unliked 13\n",
      "Unliked 14\n",
      "Unliked 15\n",
      "Unliked 16\n",
      "Unliked 17\n",
      "Unliked 18\n",
      "Unliked 19\n",
      "Unliked 20\n",
      "Unliked 21\n",
      "Unliked 22\n",
      "Unliked 23\n",
      "Unliked 24\n",
      "Unliked 25\n",
      "Unliked 26\n",
      "Unliked 27\n",
      "Unliked 28\n",
      "Unliked 29\n"
     ]
    }
   ],
   "source": [
    "#intializing count\n",
    "count=0\n",
    "\n",
    "#getting the list of all posts\n",
    "for i in driver.find_elements_by_xpath('//div[contains(@class, \"Nnq7C\")]/div/a/div[1]'):\n",
    "    #clicking on post and opening it\n",
    "    i.click()\n",
    "    \n",
    "    # explicitly waiting untill the like button is loaded\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//section[@class='ltpMr Slqrh']/span/button\")))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # locating like button\n",
    "    check = driver.find_element_by_xpath(\"//section[@class='ltpMr Slqrh']/span/button\")\n",
    "    \n",
    "    # getting the aria-label to check whether it is already liked or not\n",
    "    liked_unliked = BeautifulSoup(check.get_attribute('innerHTML'),'html.parser').find('svg').get('aria-label')\n",
    "    \n",
    "    #checking if it is liked or not\n",
    "    if liked_unliked==\"Unlike\":\n",
    "        check.click()\n",
    "        print(\"Unliked\",count)\n",
    "    else:\n",
    "        print(\"Aready Unliked\",count)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # locating the cross button to go to back page\n",
    "    back = driver.find_element_by_xpath(\"//div[@class='_2dDPU CkGkG']/div[3]/button\")\n",
    "    # clicking on cross button\n",
    "    back.click()\n",
    "    \n",
    "    #explivitly waiting until the main page is loaded again\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"Nnq7C\")]/div/a/div[1]')))\n",
    "    \n",
    "    # increasing count by 1\n",
    "    count+=1\n",
    "    \n",
    "    # checking if 30 posts are liked or not\n",
    "    if count==30:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extract list of followers \"foodtalkindia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and Opening profile \"So Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"So Delhi\" in search box\n",
    "search_box.send_keys(\"So Delhi\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of So Delhi by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"So Delhi\":\n",
    "        i.click()\n",
    "        break\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the usernames of the first 500 followers of  ‚Äòsodelhi‚Äô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mayankg07', 'shobhit.malikk', 'meenu_balwan', 'tanmay_ar', 'quotesbungut', 'seo.ranjeet', 'quotes__about__lifeee', 'khannajasmine', 'art_by_sparkle', 'mujee_dada', 'sarcastic.shadow', 'u_harsh04', 'shades_of_love.___', 'ar._vibhanshu', 'vinitkulkarni_', 'anika.singh.99', 'sarastamang', 'piya_jaiswal_08', 'shefaliscints', 'sweetweapon05', 'armaan9301', 'captyusufk', 'pratiksh_yay', 'anshikumar20', 'almatoppo77', 'foodtheka24x7', 'elly.jamson', '__rakibulislam__', 'hemantm47', 'shairabano1', 'kashyap_arora', 'pragyasharmaofficial', 'gupta._.raghav', 'kanishq_basoya_delhi0005', 'kartik_sehgal', 'joshithayadav', 'sarcastic.bacha', 'its_lucky_chouhan', 'kavyamishra19', 'satish_1020304', 'jayaaaaa_13', 'alishasingh1301', '__notpulakita__', 'rizvi3144', 'adimac1', 'vaishnav_boy_yogesh', 'srinithya.k30', 'nirav_0004', 'karan_mathpal14', 'abhishekmishra1662', 'mehtageeta57', 'motivationalsms', 'hardeepdeeep', 'swati_mital', 'jiyaachugh_05', 'swarsrushti98', 'tanvishkula', 'vk156890', 'vviikkaas', 'suhaaannnzzz', 'rupali.dua', 'swati_mishra30', 'fusion_chaat', 'veggiebychoice', 'khan_muskaaaaaan', 'simransoni805', 'zia.theexplorer', 'praachisaxina', 'ace__2007', 'vodka_0.49578', 'vaishh.007', 'banikarana', 'sheebakochhar', 'shourya.groverr', 'ariba_usman', 'folk.ways15', '_sheena.bhatia_', '_deliciousss__food_', 'srishti_2611', 'tarinigoyal27', 'a_humane_being', 'suryansh2378', 'dabas_vj', '_have_some_fun_69', 'aishwaryasudarsanan', '_sakshi_garg_', 'rahul_gupta211', 'rudrakshi.deo', 'lilcrazybitchx', 'chandankumar.yaduvanshi', 'shyam.arora.7967', '_writing_for_healing_', 'manav11142', 'naghman2020', 'mr.ali_hamza', 'vanraj_vala_11', 'rishabhpandey1432', 'this.is.life.dw', 'parteet_kaur', 'santtosha', 'zdekhani', 'shubhamsharmaaaaaaaaaa', 'aliya_jameel21', 'va.nsh2184', 'iam_sagittarius_girl', '_spirited_traveller_', 'lata10724', 'sameerkhan5981', 'shilpa_khari_bhati', 'happy.beinggg', 'dalalnaguransandeep', 'suresh.sunar', 'shanti_bk', 'brindhagovindaraj03', 'quote_ki_duniya90', 'prathamaswal', 'sunny_unofficial', 'foramthakral', 'thewokincloset', 'annieshrivastaw', 'n.u.m.a__', 'im_bikashjena', '_chenab__', 'paramjit_chawla', 'cuisineflavours', 'shall_usehrawat', 'sumati_kohli', 'saima.khushi', 'tanugarg_', 'aap_india_2020', 'neharika_s', 'mukeshmoond137', 'laakshakakkar05', 'erotixindia', 'msr.pvt', 'aishitha_777', 'arunkumar3298', 'prabhiman.97', 'adultjocks', '014devil_evil_', 'hunger.heights', 'explorediscovercreateee', 'shivaa_mani', 'devangshu96', 'aggarwalabhinandini', 'chahatsusawat_', 'picky_silky', 'parthsehgal.620', 'sthakur', 'masakalliiii', 'mittal_sarthak7', 'deepti1659', 'dhruv__shresth', 'paresh_deshmukh02', '100rabh_glimpse', 'nikkib2610', 'deep.typewriter', 'sakshi28garg', 'rushabh_savla_', 'sonu3499yadav', 'smritiaggarwal07', 'vartika___arora', 'dr.shibamirza94', 'aastha_sharma0402', 'mananjandyal', 'muskan_mathpal', 'tiwari_shandilya', 'livinbloomin', 'delhifoodiecouple', 'prernaaa_00', 'vaishnavi___x', 'sebastiannn.29', 'panthemang', 'ashi_dreaming', 'soniya__.k', 'dakshdevgan', 'yashashwini_tak', 'pawa5568', 'dakshsiingh', 'itz_diwa.kar', 'ms.b.p.c', '_holger_schultz_', 'diwanshiaggarwal', 'anishvashisht04', 'social_329', '_charusingh19', 'panshiiii', 'mj_caterers', 'adirathgoswami_', 'kirangandhi89', 'vijayduttdwi1987', 'mahadev_9188', 'aliiiittlebitdrunk', '_itz_india_', 'saggychops7', 'tribhuvansharmaa', 'random_stuff.055', 'visvan_', 'prav3111', 'high_hoke_hasle', 'shahbaz__khan02', 'forbidden_voices__', 'ngovanhoan1', 'varunkhatana69', 'pranshuitheaahe', 'silrajpoot', 'sharlz.po', '_r_i_s_h_a_v_07', '_lockedinthehaze_', 'hemavarshini_jayakumar', 'yana_rao', 'vaniarora2206', 'rusha.chatterjee_', 'vegetarianbug', 'aakashsharma516', 'faded_sxars', 'nikhilgujjar_official', 'parveengehl', 'saumya_kakandwar', 'sahrawat_astu16', 'preetiaery', 'calmlycalmdown', 'jyoti9414', 'shashank_1', 'aapurva7', 'ekik.singhal', 'mr_sachin01', 'momoandart', 'angelicpearllima', 'ana.nya09', 'vipul_live', 'bababulletwale', 'bhaskarsolanki7', 'shekhsamar8', 'imdakshkumar', 'jindalsrishti', 'nehapatawari', 'raghav.agrawal26', 'smita.v.mishra', 'tramptraveler', 'matarchicken_', 'nabe3dayon', 'whosaifansari', 'id_ishika', 'escaped___flavors', 'aleed_sial.29', 'prince_112_1', 'edmhackerhouse', 'lifetime_travel_diaries', '_street_food_nagpur', 'nidhipriya04', '_merchantayaan.1', 'monicachauhan.17', 'ranjan.kumar297', 'chauhanbitto', '5.qwerty.6', 'bla.ah05', 'nitishbhardwaj2310', 'rahul.1422', 'hammyhimanshu', 'dreamified_soul', 'foodie_duo__', 'vipin7109kumar', 'akhilahuja7', 'kadyrbekov.21', 'ayuzhma', 'praveen7017kumar', 'antu__iams', '__klickerz__', '_football__freak__', '_.samachar._', 'utk_the_sailor', 'intriguing_illusion', 'kiranaeren', 'picturesque_nas', 'israt.jahan._juii', '_anika_choudhary', 'eshhsha', 'rishavvirat', 'amitnd_', 'thebiblepreaching', 'm_ur_amrit', 'nadiafatima99', '_i_am_himanshu_', 'akshat27.p', 'mdshadabraftaar3', 'tapan_zena', 'aslam_ansar_03', 'filmy.vivek', 'the_anu_001', 'premiumquotes.app', 'dushyantbhatia02', 'puja_vyas2006', 'radhika_khanna16', 'angchumi_rajkhowa', 'shubhams_saka', 'rastogi_umang', 'bikrambahadurnepal', 'arafat.ullah.5', 'nikhilltiwari', 'neetusingh449', 'vinni.im', 'girlshottts', 'agrahub', 'bor.afi', 'barkha68', 'mayankverma024', 'aravindrawat', 'likhitme', 'kashikapvt', 'sachincool', 'l.l1k', 'muthuhm007', 'siddhantarneja', 'missasia4', 'safasafa7835', 'robin__uniyal', 'himanshu_saini_18', 'deepikasomwal', 'strbry_shotcake', 'suraxj.baudh', 'jain.usit', 'ablaze280', 'animateurvantsang', 'hrsu___', 'shakti_tanwar', 'the_guru_ag', 'arzu.raval', 'parth_jarvis', 'rishabh_dh', 'mansigulati2210', 'karn91g', 'siakhanna', 's_ishpreet_kaur', 'inimadepiatra75', 'absolutelysanjana', 'komi.cherry.love', 'imranfarooq0322', 'binny_purohit', 'princyb.143', 'chinnadua', 'theaestheticthread', 'sonalikapuri', 'triedntasted_', 'ameeshaa.g', 'neuherbs', 'vanshikagarg_03', 'guptamanaswini', 'heenakouser146', 'vibhubansal_11', 'twists_and_turns8', 'neetamittaljajodia', 'vaibhavramrakhiani', 'gossip_xoxxoxo', 'rtvibes1907', 'pallavig_98', 'royalrajput6883', 'iuc_.malik', 'sarmistha.dutta.568632', 'pratzilla_', '_snacking_sisters', 'prachi.kumar777', 'poonam_13singh', 'roshnisushilgujjar004208', '_vasundhara', 'manyamalik', 'rajeev__chaudhry', 'haritagrawala', 'yourindiagram', 'fuzzi__', 'namaswi_writes', 'yaitstan', 'formen_athelete', 'nagi_pankaj', 'akanshaa_14', 'thefoodc', 'harshita_aaaa', 'yaatindawar', 'justforlaughs_gagss', 'mr_manihar71', '__oxalic_acid__', 'prernasharmam93', 'foodieninjaz', 'sonu209singh6', 'food_food_official__', 'comfortingprospect', 'simaktn', 'creative_creations30', 'quotespostin', 'amitkhobra18', 'sakshamjain_19', 'tvg_23', 'kashina_chadha', 'rubiyarangrej111', 'shannonmariekraines', 'rajoria_nick', 'noorcreations._', 'reshma_abhishek', 'passmymartini', 'azmifatima78', 'balkishan5836', 'pinkymayank', 'lakshminarayanan26', 'aartimadan', 'thegirlwhoclicks__', 'vandanadiddee', 'ridhima783', 'tripppingindia', 'sakshi._.singhal', 'harshit2755', 'dharmendar2651', 'bunnysingh001', 'iamusmantanveer', '100rabh_vishnoi', 'rockwoodschool.in', 'sancks_with_me.in', 'shh.reyyaaa', 'shuchi2526', 'sunitajain2055', 'saurabh.arora1511', 'shubhamspideyterminator', 'anshuls958', 'times.of.portrait', 'srishtigera77', 'bhola9988', 'nishantsethi', 'just_to_write_right', 'vineetbhola24', 'all_types_quote', 'kumawat_boy028', 'street_food_punjab', '_iamdk_', 'nikssssss_1', 'anitekbhattacharya', 'chef.archanabansal', 'sklive_official', 'hiren_panchal_1005', 'a_anabella', 'shivani_shekar19', 'ruchi_radhya', 'as_design_atelier', 'priya.saini95', 'hindi.quote', 'apurva_yandra', 'wmfat', 'nishk46', 'impressions_kugraphy', 'komalgrover20', 'hardiktak', 'lakshyraj_singh_rathore_', 'jeewanrajendersingh', 'happy_gurjar_official', 'prakash1698magiliniyaal', 'devilishlydelicious2020', 'chetalibatra', 'kinicooks', 'i_am_kalpesh_561_', 'rads.chhabra', 'akhil_sethi', 'narottemkumawat', 'manishj4u', '___born__2__win', 'rania.omarrr', '_itwillbefine__', 'asiffism_', 'soulssmileclub', '786sv', 'kaxoka7204', 'sumit.7018', 'simranpreet.singh.12', 'riyasethi_011', 'patel.mona.3348', 'foodaholic_bae', '_megsingh_07', 'maniisha1234', 'simrangrover89', 'dipanshu_chauhan_', 'shivanigautam0812', 'picturesandpoets.in', 'bhawanaabbott', 'worktopbusiness', 'pavit7507', 'enasinghania', 'netflix.amazonprime.sales', 'bhaiji_iam', 'aj.aman029', 'anirudh.sondhi', 'timelenstoken', 'delhi_foodies_hub', 'azehrra', 'ishiitaa_k', 'kuma.r5443', 'sankhan8478', '_gautam_08', 'kanhakaahyap', '__.story_teller.__', 'sohanijenamani.jpg', 'madhavibhoyar', 'pooja1410', 'mr__perfect.77']\n"
     ]
    }
   ],
   "source": [
    "# locating the followers link\n",
    "followers = driver.find_element_by_partial_link_text(\"followers\")\n",
    "#clicking on followers link\n",
    "followers.click()\n",
    "\n",
    "#explicitly waiting until the followers list loads completely\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//a[contains(@class, \"notranslate\")]')))\n",
    "\n",
    "\n",
    "# fetching the top 500 followers\n",
    "# doing it in a while true loop unitl we got first 500\n",
    "while True:\n",
    "    #using exception staleelementreferenceexception\n",
    "    try:\n",
    "        #creating a list in which the usernames is to be stored\n",
    "        sodelhi=[]\n",
    "        \n",
    "        # mainting count\n",
    "        count=0\n",
    "        while True:\n",
    "            # locating the usernames of followers\n",
    "            u_element = driver.find_elements_by_xpath('//a[contains(@class, \"notranslate\")]')\n",
    "            \n",
    "            #checking if we got the first 500 or not\n",
    "            if len(u_element)<500:\n",
    "                \n",
    "                #exlicitly waiting until the list is loaded completly\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//ul[contains(@class, \"jSC57\")]')))\n",
    "                \n",
    "                #scrolling the window\n",
    "                driver.execute_script('arguments[0].scrollIntoView(0, 100);', driver.find_element_by_xpath('//ul[contains(@class, \"jSC57\")]'))\n",
    "                time.sleep(1)\n",
    "                \n",
    "            #getting the top username on the window\n",
    "            i=u_element[count]\n",
    "            #appending the username to the sodelhi list\n",
    "            sodelhi.append(i.get_attribute('innerHTML'))\n",
    "            if len(sodelhi)>=500:\n",
    "                break\n",
    "            count+=1\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        continue\n",
    "\n",
    "print(sodelhi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and Opening profile \"foodtalkindia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"foodtalkindia\" in search box\n",
    "search_box.send_keys(\"foodtalkindia\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of foodtalkindia by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"foodtalkindia\"\":\n",
    "        i.click()\n",
    "        break\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the usernames of the first 500 followers of  ‚Äòfoodtalkindia‚Äô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sammedpatil4252', 'pari_gala', 'taste_crusaders009', 'srishhh_20', 'srishhh_pvttt', 'mryogeshdwivedi', 'yadavking0', 'sonu_singh17', 'arjunkohli1984', 'mastersincooking', 'bansaln', 'yeshdcool.9', 'chinusculinarytales', 'shajidas4ms', 'stir.fried_stories', '_london__boy_', 'zautam', 'dharam____dwivedi', 'garlinism', 'vipinaggarwalphotography', 'chefakhileshdahima', 'giiljoban', 'i_am_pallabi_chanda', 'beenthereatethatt', 'sangeetmalhotra9', 'wanderwall13', 'aman__mirza__01', 'tendercoconut88', 'cheatdayoinkers', 'roko_eats', 'mr_pravin_0990', 'kriticalmehra', 'miss_grish', 'niteshkumar1481', 'daman_bhandari', 'bobo__2311', 'fiftyshades692', 'fairy_angel2516', 'antique_atique', 'chef_surjeet_', 'foodish_sensualist', 'anshikawalani_', 'amikarn', 'ra.fik3105', 'ragya_rsb', 'nileshkumarpareek.official', 'sunil_vishwakarma.official', 'eat.laugh.dance', '____desi_swag____', 'r.rachana', 'thatbombae_girl', 'vibha1703', 'gossedit24', 'chefsachendrarana', 'prince_royce6688', 'y.u.m_y.u.m.m.y_y.u.m', 'mrigankkeshav', 'shashanks_kitchen', 'ayush0413', 'gohil3638', 'miss_rathorefoodie', 'its_m_e_foodie_007', 'ancient_kitchen', 'mohamedriaazfakie', 'clickalmost', 'vinay_22_', 'barodian_foodie', 'the.tapestrybysathia', '_royal_king_351', 'maujmaahmedabad', 'amreshsharma88', '1out.of.world', '_looser._.bad__', 'boby_sid_786', 'notthatblah_2516', 'trupti.marolia', 'inconsolable_soul1212', 'kopalr', 'tarunam1993', 'foodieaappaa', 'kinicooks', 'marci447', 'lavy___aulakh', 'sameer_cute_x', 'akshaysharma539', 'shubh__banna', 'nilesh_gothe', 'sid_n94', 'rucksackandbackpacks', 'veetu_food_factory', 'nancy.multani', 'momentomori.322', 'wierdthougths', 'arpanbhargava', 's.k.rajkumar_official', 'banjaarafoodie', 'rocky76176', 'bhowmickgubli_2127', 'aggarwal.siddharth1', 'shreya_srivastavaa', 'devendra_lonari', 'p_l_a_y_b_o_y88', 'amolsolanke219', 'sasssygirl_', 'ghareluzaika_', '_dio_rafi', '__v_key___xx_', 'sandujakannu', 'rs_5990', 'chef_kml', 'mathewharris', 'khush_i303', 'naeem123819', 'justanotherhmaccount', 'ladybeezwezwe', 'madrasdiaries_', 'dhamitanvir', 'varshitaravindranathan', 'duttasubasana', 'foodieachayan', 'luscious_madewithlove', 'kritika.mittal.184', 'drooling_over_', 'siddharth_s_s', 'swetasaharia.mini', 'the_food_philosophy25', 'pramil09', 'prashant.madaan', 'himanshusharma7344', 'ashah6904', '___pragnesh', 'express_with_food', 'amith_396', 'thakursha56', 'apeksha_somaiya', 'neelamrakhra', 'alisha_rajput_fan_club', 'maharashtra.legacy', 'sahil070596', 'salman_s_khan_13', 'the_indi_world', 'thathealthymeal', 'ajaygraphix', 'shirishagangula', '_.enchanted101._', 'radhikanathani', 'mirzamirzanisha', 'akankshak1141', 'foodie_chef_house.07', 'madhu_reddy_9', 'sumith6174', 'mahendra_choudhary.12', 'rad.baker', '_rain_bow_2006', 'saur_1629', 'mr_gk_24', 'rajsankapal', 'road.to.mytummy', 'aishwarya_kaushii', 'kuchdinstayin', 'grand_rose_123', 'mr__ss__sonu__07__', 'shiva_.24._', 'kalotarasanjay', 'sunita_dube', 'thunder_boy786', 'aniketdeb6', 'spacemgmt', 'navya_kajjam', 'pallavipinki16', 'meharkhankhan', 'anitakalro', 'bagel._.12', 'flavourscape', 'mr.niks_ptl', 'frhanakhtr786', 'kandepoheanibarachkahi', 'hemani.agrawal', 'vidushi.g.agarwal', 'imjassasidhu', 'jyot_1113', 'baisakhdas', 'my_explorations_in_life', 'arkamitraroy', 'existential_flux', 'awaiz_mirza__', 'kevin.24072407', 'ell.o.ess', '___mahadev_ka_ladla__', 'mr_kp__13', 'ijaj_ahmed_78', 'cooking7671', 'rahul_sikder_143', 'foods_thattempt', 'alkapatel2110', 'enirohaeniiiii', 'bringsomebrocolli', 'sriya_luv', '05_renu', 'masharibtaslim', 'life_of_sangeetha', 'dharmendra.chowdhury.9', 'daawatebiriyani', 'mahinoor5280', 'wsx7755332018', 'v_nilesh777', 'imdhruvpsingh', 'krishnakishorereddy', 'mr._na_re_nd_ra', 'kangscookingcorner', 'musheer_shami', 'radhika_9430', 'sonam2411', 'shah.alesh', 'nalinisrivastava25', 'sauravsamanta_', 'taroonishw', 'the_imbible', 'sizzling_food_cravings', 'nandiniimaheshwari', 'sethu_kadaikal', 'prem.sangita', 'kureel_neha', 'irshad_ali_saifi_', 'foodforfoodiesworld', 'glourmet', 'mohmmad.ishak.71', 'nandinipandit1705', 'mostafa_bazazoff', '_foodie_bro', '5thirty666', 'geetabhushan1548', 'im_karanmalhotra', 'a_curry_tale', 'manleen2712', 'anjanakrrish', 'lolklolk7', 'theritzcarltonpune', 'malik_rubab7', 'in.nehaagrawal', 'nirupamborgohain', 'qwikvines', 'priyanka.desai.kapadi', 'bhasinraul', 'hemalshah_77', 'mansi_khandelwal10', 'drink.studio', 'khana_so.jana', 'prxxyx_4', 'srdllshykh', '_000_nitin', 'foodarmyan', 'sudheerkumarbhardwaj', 'healthyway.in', 'cookbook365', 'recipe18naina', 'ashiish.a', 'tanvi1601', 'thefoodmela', 'sharmilee_mitra', 'vaishnavitannu', 'bheenikapur', 'neena4944', 'missramjam', '_ctm.events.and.pr_', 'thefoodshow.in', 'viddyanair', 'suriti.gupta.121', 'foodindia98', 'konkan_bites', 'vrindadancestudio', 'a_man_rj', 'craversbooty', 'veggiebychoice', 'ace__2007', 'mannarrajesh_', 'ashishverma1844', 'gillu_07', 'foodie_talkes', 'poojarani165', '_onecherish_.click._', 'nfseller', 'aravind_chelliah', 'manisreekar', 'anudeep25', 'udayababu264', '_muhammed_shaheen_07', 'nikumbh304', 'nishakulbangalore', 'kishan.yana', 'eatsfoodie_itsdelhi', 'souvik_1988', 'the_street_bawarchi', 'fezahil_99', 'raghav_zuge', 'surendra_2410', 'trottersjaisalmer', '__v.a.i.s.h.a.l.i__', 'donttellmewhattodoo_', 'suanahaisafar', 'food_with_lazra', 'manikas._.kitchen', 'creationcreative27', 'vinay.sharma.5205622', 'foodkafood_panikapani', '_._mayank_._17x', 'capricon_chefs', 'pappi_ta_lelo', 'explorediscovercreateee', 'rsb__offical', 'jyotimehta34', 'mahajan_meha', 'hipsterdiaries', 'surjit.kaur.750546', 'ablaze280', 'my_life_is_joyful_', 'ojesh.agrawal', 'bhagyashreechunekar', 'pritam.rajput.9009', 'pavii95', 'niyati_mordani', 'itsme_nidhi19', 'foodify2020', 'haris_shahid_ansari', 'naeemahmad2536', 'rutikapanikker', 'vandan_thakkar', '999_ravisharma_999', 'makwana.1969', 'modelschoicee', '_craving_hut_', 'amar_jindal', '_itz_india_', 'iamvickeeypandit', 'food_with_ruchit_jaiswal', 'ngovanhoan1', 'nawal.magar.351', 'harshada_shubhangi_anant_ambre', 'foodie_way2', 'rohan3798', 'foodie.bypassion', 'not_too_common', 'rizwanansari7500', 'yeda_boxer', 'sahay_monika', 'sonalarora26', 'lokaviaa', '_monika.arora_', 'foodeefeelgood', 'shivaleelahiregoudar', 'farmtofork.solution', 'jyoti_rana456', 'hraei1961', 'vishavjeetsingh050', 'ronika.ayiroor', 'wtf_wheresthefood__', 'alish_joe', 'akash_v93', 'mo.shamikhan_72', 'asmaruf21', 'shiksha.saraogi', 'oshin.jain.583', 'z.i.j.n.a', 'piyush_sharmaa_', 'iamnaveenkumar7', '_magnificent_.jelly', 'foodlover_kets', 'teamcravings', 'vogueveggielovers', 'devikashivhare17', 'shukla_ansh19', 'thegirllwhobakes', 'kadyrbekov.21', 'i.love.food.20.20', 'deep20065', 'urfoodguyde', 'the_unstable_soul', 'explore.beautyof.india', 'yummyytummyy0409', 'utk_the_sailor', 'anant_trivedee', 'shal_293', '__foodiefromawomb.___', 'adda.bouzid.1', 'sru_t_sth', 'foodie_happy_yatra', 'desigourmetguy', 'taru605', 'shaikh87.sumi', 'prajwal_b_k', 'cravingsofdee', 'singh.purusharth', 'avishbansal08', 'sheshu.999', 'pradyuth_krishna', 'sarita19devi93', 'mehyeri_', 'imjd8887', 'happyhoneyhasini', '__s.h.r.e.y.u', 'rahuldesousa', 'aryaendrashekhar', 'ikirti_srivastava', 'nipun_beniwal', 'anticipatorybaid', 'ishanonly', 'sonaltakiyar', 'bee_piripiri', 'shivu086', 'yaminichander', '_imainak_roy_', 'mustang.raj', 'chal_khate_hai', 'buttercupwho_', 'foooodpad', 'deepank_singhal', 'princy_shamim', 'badie_a_', 'paras_info', 'thepatriwala', 'aakashdubey0306', 'thepilatesstudio2019', '_food_magnifique_', 'baranwaltanvi', '11preetarora', 'noonis_kitchen', 'abhay_paikrav', 'knife_and_forks', 'ishita.kothari', '01vitaa', 'yourindiagram', 'arif_ariz', 'neemabhumik', 'cookingwitharadhika', '_____1912__', 'haritagrawala', '_abhinavkapur', 'vai5hvik_desai98', 'foodish_woodish', 'anusha041', 'sonal0723', 'shrutiityagi', 'foodieworld___', 'athul_tdharan', 'siddhi11028', 'sakshi_gupta_s', 'shahbaz0756', '__thehungrybelly__', 'flowerbeanbella', 'khaaadad', 'foodoutletindia', 'prabhakaransuraj', 'thesaint.co', 'ad17y_raj', 'official.xamaan', '_.adatewithfood._', 'vishalbeardo', 'curvacious_fashionista', 'nashikfarms', 'nanamora2020', 'n_a_r_a_y_a_n_a_n.mn', 'imprashxnt', 'gurpreet_9977', 'mr__pro__official_', 'merlynkeziah', 'diyadey_998', 'nairan_anridh_obsession', 'aishwaryamunjal', 'macch_eese', 'jasonroy6925', 'foood_cravingz', 'ubadajukaku', 'theycallmeiriss', 'ameyarathod', 'mridulmehrotra', 'natashajyoti', 'foodielangar', 'pranjul_shing_rawat', 'vibhor477', 'deepakmehra_chef', 'd_a_i_r_y_m_i_l_k_b_a_de', 'aashigupta2801', 'hey__exy____', 'thetastingpalette', 'varshagola', 'mealhomecooked', 'just______adi', 'chef.archanabansal', 'dhanukasarvan', 'fyroozmuhammad', '_amit__chauhan__', 'salujabhavnesh', 'cookingshookingepicurean', 'nishk46', 'everythingspiceandverynice', 'hardiktak', 'that.tastes.delicious', 'happy_gurjar_official', 'devilishlydelicious2020', 'dinesh.mehtani.16']\n"
     ]
    }
   ],
   "source": [
    "# locating the followers link\n",
    "followers = driver.find_element_by_partial_link_text(\"followers\")\n",
    "#clicking on followers link\n",
    "followers.click()\n",
    "\n",
    "#explicitly waiting until the followers list loads completely\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//a[contains(@class, \"notranslate\")]')))\n",
    "\n",
    "\n",
    "# fetching the top 500 followers\n",
    "# doing it in a while true loop unitl we got first 500\n",
    "while True:\n",
    "    #using exception staleelementreferenceexception\n",
    "    try:\n",
    "        #creating a list in which the usernames is to be stored\n",
    "        foodtalkindia=[]\n",
    "        \n",
    "        # mainting count\n",
    "        count=0\n",
    "        while True:\n",
    "            # locating the usernames of followers\n",
    "            u_element = driver.find_elements_by_xpath('//a[contains(@class, \"notranslate\")]')\n",
    "            \n",
    "            #checking if we got the first 500 or not\n",
    "            if len(u_element)<500:\n",
    "                \n",
    "                #exlicitly waiting until the list is loaded completly\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//ul[contains(@class, \"jSC57\")]')))\n",
    "                \n",
    "                #scrolling the window\n",
    "                driver.execute_script('arguments[0].scrollIntoView(0, 100);', driver.find_element_by_xpath('//ul[contains(@class, \"jSC57\")]'))\n",
    "                time.sleep(1)\n",
    "                \n",
    "            #getting the top username on the window\n",
    "            i=u_element[count]\n",
    "            #appending the username to the sodelhi list\n",
    "            foodtalkindia.append(i.get_attribute('innerHTML'))\n",
    "            if len(foodtalkindia)>=500:\n",
    "                break\n",
    "            count+=1\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        continue\n",
    "print(foodtalkindia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_element_by_xpath('//div[contains(@class, \"eiUFA\")]/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### followers of ‚Äúfoodtalkindia‚Äù that you are following but those who don‚Äôt follow you.\n",
    "\n",
    "I did this by extracting and saving a list of all the user's followers(myfollowers) and those who are followed by the user(following). and getting the answer by using \"(followers_of_foodtalkindia_that_user_is_following)-(user's_followers)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_profile = driver.find_element_by_xpath('//div[@class=\"_47KiJ\"]/div[5]/span/img')\n",
    "my_profile.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'zwlfE')))\n",
    "\n",
    "total_following = driver.find_element_by_xpath('//ul[@class=\"k9GMp \"]/li[3]/a/span').get_attribute(\"innerHTML\")\n",
    "\n",
    "following_link = driver.find_element_by_partial_link_text(\"following\")\n",
    "following_link.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'PZuss')))\n",
    "\n",
    "\n",
    "current_height = driver.execute_script('return document.querySelector(\".PZuss\").offsetHeight;')           \n",
    "while True :\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0,\"current_height\");',driver.find_element_by_xpath('//div[contains(@class, \"PZuss\")]'))\n",
    "    time.sleep(3)\n",
    "    new_height = driver.execute_script('return document.querySelector(\".PZuss\").offsetHeight;')\n",
    "    if new_height == current_height :\n",
    "        break\n",
    "    current_height = new_height\n",
    "\n",
    "    \n",
    "while True:\n",
    "    try:\n",
    "        my_following = []\n",
    "        \n",
    "        # mainting count\n",
    "        count=0\n",
    "        \n",
    "        # locating the usernames of followers\n",
    "        u_element = driver.find_elements_by_xpath('//a[contains(@class, \"notranslate\")]')\n",
    "        \n",
    "        while count<len(u_element):\n",
    "            i=u_element[count]\n",
    "            \n",
    "            #appending the username to the my_following list\n",
    "            my_following.append(i.get_attribute('innerHTML'))\n",
    "            \n",
    "            count+=1\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_element_by_xpath('//div[contains(@class, \"eiUFA\")]/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'zwlfE')))\n",
    "\n",
    "total_followers = driver.find_element_by_xpath('//ul[@class=\"k9GMp \"]/li[2]/a/span').get_attribute(\"innerHTML\")\n",
    "\n",
    "followers_link = driver.find_element_by_partial_link_text(\"followers\")\n",
    "followers_link.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'PZuss')))\n",
    "\n",
    "current_height = driver.execute_script('return document.querySelector(\".PZuss\").offsetHeight;')           \n",
    "while True :\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0,\"current_height\");',driver.find_element_by_xpath('//div[contains(@class, \"PZuss\")]'))\n",
    "    time.sleep(3)\n",
    "    new_height = driver.execute_script('return document.querySelector(\".PZuss\").offsetHeight;')\n",
    "    if new_height == current_height :\n",
    "        break\n",
    "    current_height = new_height\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        my_followers = []\n",
    "        \n",
    "        # mainting count\n",
    "        count=0\n",
    "        \n",
    "        # locating the usernames of followers\n",
    "        u_element = driver.find_elements_by_xpath('//a[contains(@class, \"notranslate\")]')\n",
    "        \n",
    "        while count<len(u_element):\n",
    "            i=u_element[count]\n",
    "            \n",
    "            #appending the username to the my_following list\n",
    "            my_followers.append(i.get_attribute('innerHTML'))\n",
    "            \n",
    "            count+=1\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_element_by_xpath('//div[contains(@class, \"eiUFA\")]/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Followers of foodtalkindia followed by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"foodtalkindia\" in search box\n",
    "search_box.send_keys(\"foodtalkindia\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of foodtalkindia by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"foodtalkindia\"\":\n",
    "        i.click()\n",
    "        break\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'zwlfE')))\n",
    "\n",
    "followed_by = driver.find_element_by_partial_link_text(\"Followed by\")\n",
    "followed_by.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME ,'SfPzb')))\n",
    "\n",
    "\n",
    "see_all_followers = driver.find_element_by_partial_link_text(\"See All Followers\")\n",
    "see_all_followers.click()\n",
    "\n",
    "while True:\n",
    "    #using exception staleelementreferenceexception\n",
    "    try:\n",
    "        #creating a list in which the usernames is to be stored\n",
    "        foodtalkindia_followed_by_me = []\n",
    "        \n",
    "        # mainting count\n",
    "        count=0\n",
    "        while True:\n",
    "            # locating the usernames of followers\n",
    "            u_element = driver.find_elements_by_xpath('//a[contains(@class, \"notranslate\")]')\n",
    "            \n",
    "            #checking if we got the first 500 or not\n",
    "            if len(u_element)<len(my_following):\n",
    "                \n",
    "                #exlicitly waiting until the list is loaded completly\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//ul[contains(@class, \"jSC57\")]')))\n",
    "                \n",
    "                #scrolling the window\n",
    "                driver.execute_script('arguments[0].scrollIntoView(0, 100);', driver.find_element_by_xpath('//ul[contains(@class, \"jSC57\")]'))\n",
    "                time.sleep(1)\n",
    "                \n",
    "            #getting the top username on the window\n",
    "            i=u_element[count]\n",
    "            #appending the username to the sodelhi list\n",
    "            foodtalkindia_followed_by_me.append(i.get_attribute('innerHTML'))\n",
    "            if len(foodtalkindia_followed_by_me)>=len(my_following):\n",
    "                break\n",
    "            count+=1\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = driver.find_element_by_xpath('//div[contains(@class, \"eiUFA\")]/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now finding the followers of ‚Äúfoodtalkindia‚Äù that I am following but those who don‚Äôt follow me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beenthereatethatt\n",
      "dlfmallofindia\n",
      "bobo__2311\n",
      "stir.fried_stories\n",
      "chinusculinarytales\n",
      "yaprs7\n",
      "wanderwall13\n",
      "aman__mirza__01\n",
      "ananyaburman\n",
      "mryogeshdwivedi\n",
      "i_am_pallabi_chanda\n",
      "roko_eats\n",
      "sammedpatil4252\n"
     ]
    }
   ],
   "source": [
    "my_following = set(my_following)\n",
    "my_followers = set(my_followers)\n",
    "\n",
    "foodtalkindia_followed_by_me = set(foodtalkindia_followed_by_me)\n",
    "\n",
    "my_following_who_dont_follow_me = my_following - my_followers\n",
    "\n",
    "foodtalkindia_followed_by_me_who_dont_follow_me = foodtalkindia_followed_by_me.intersection(my_following_who_dont_follow_me)\n",
    "\n",
    "for i in foodtalkindia_followed_by_me_who_dont_follow_me:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.  story of ‚Äòcoding.ninjas‚Äô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opening profile of coding.ninjas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating and enabling the search by clicking on it\n",
    "search_enable = driver.find_element_by_class_name('TqC_a')\n",
    "search_enable.click()\n",
    "\n",
    "# explicitly waiting until the search box is enabled\n",
    "search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"XTCLo\")))\n",
    "\n",
    "# writing \"coding.ninjas\" in search box\n",
    "search_box.send_keys(\"coding.ninjas\")\n",
    "\n",
    "# Explicitly waiting until the search result loads\n",
    "WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,\"fuqBx\")))\n",
    "\n",
    "# Openeing the profile of coding.ninjas by clicking on the search result\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"Ap253\"]'):\n",
    "    if i.get_attribute(\"innerHTML\")==\"coding.ninjas\"\":\n",
    "        i.click()\n",
    "        break\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_6VtSN\")))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story Already seen\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    story = driver.find_element_by_xpath(\"//div[@class='RR-M- h5uC0']\")\n",
    "    story_exists = True\n",
    "except:\n",
    "    story_exists = False\n",
    "    \n",
    "if story_exists:\n",
    "    if driver.find_element_by_xpath(\"//div[@class='RR-M- h5uC0']/canvas\").value_of_css_property(\"top\")==\"-8px\":\n",
    "        print(\"Story Already seen\")\n",
    "    else:\n",
    "        story.click()\n",
    "        print(\"Seeing story now\")\n",
    "else:\n",
    "    print(\"No story available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
